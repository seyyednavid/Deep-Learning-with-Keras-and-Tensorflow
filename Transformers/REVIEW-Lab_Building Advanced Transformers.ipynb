{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m823.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.8/391.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyarrow, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.29.2 pyarrow-18.1.0 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m126.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m26.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 12:12:07.943239: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-02 12:12:07.945646: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-02 12:12:07.949712: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-02 12:12:07.961020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735819927.979818      84 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735819927.985407      84 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-02 12:12:08.005429: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 12:23:23.560570: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 1s/step - loss: 12.8287\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 1s/step - loss: 0.2128\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 971ms/step - loss: 0.2085\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1446\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 961ms/step - loss: 0.1214\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 959ms/step - loss: 0.1292\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 966ms/step - loss: 0.1860\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 967ms/step - loss: 0.1842\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 967ms/step - loss: 0.1588\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 968ms/step - loss: 0.1277\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 959ms/step - loss: 0.1193\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 957ms/step - loss: 0.1067\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 977ms/step - loss: 0.0799\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 952ms/step - loss: 0.0991\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 966ms/step - loss: 0.0677\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 969ms/step - loss: 0.0979\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 972ms/step - loss: 0.0921\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 971ms/step - loss: 0.1080\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 973ms/step - loss: 0.0592\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 947ms/step - loss: 0.0671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f36c83fa290>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 302ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(data, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
